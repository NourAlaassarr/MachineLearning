{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXnPq5Fsw8iZ",
        "outputId": "65a220e7-977f-4f72-c9e6-2ca1be662b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k value: 26\n",
            "Number of correctly classified instances: 183\n",
            "Total number of instances: 231\n",
            "Accuracy: 79.22%\n",
            "\n",
            "k value: 27\n",
            "Number of correctly classified instances: 181\n",
            "Total number of instances: 231\n",
            "Accuracy: 78.35%\n",
            "\n",
            "k value: 28\n",
            "Number of correctly classified instances: 181\n",
            "Total number of instances: 231\n",
            "Accuracy: 78.35%\n",
            "\n",
            "Average Accuracy Across All Iterations: 78.64%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the diabetes dataset\n",
        "df = pd.read_csv('diabetes (1).csv')\n",
        "\n",
        "# Function for Min-Max Scaling\n",
        "def min_max_scaling(data):\n",
        "    min_vals = np.min(data, axis=0)\n",
        "    max_vals = np.max(data, axis=0)\n",
        "    scaled_data = (data - min_vals) / (max_vals - min_vals)\n",
        "    return scaled_data\n",
        "\n",
        "# Function for computing Euclidean distance\n",
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "# Function to perform KNN classification\n",
        "def knn_classify(train_data, train_labels, test_instance, k):\n",
        "    distances = np.zeros(len(train_data))\n",
        "\n",
        "    for i in range(len(train_data)):\n",
        "        distances[i] = euclidean_distance(train_data[i], test_instance)\n",
        "\n",
        "    # Get indices of k nearest neighbors\n",
        "    k_neighbors_indices = np.argsort(distances)[:k]\n",
        "\n",
        "    # Use Distance-Weighted Voting to break ties\n",
        "    class_votes = {}\n",
        "    for idx in k_neighbors_indices:\n",
        "        label = train_labels[idx]\n",
        "        weight = 1 / distances[idx]  # Inverse of distance\n",
        "        class_votes[label] = class_votes.get(label, 0) + weight\n",
        "\n",
        "    # Return the class with the highest weighted votes\n",
        "    return max(class_votes, key=class_votes.get)\n",
        "\n",
        "# Function to split data into training and testing sets\n",
        "def train_test_split(data, labels, split_ratio=0.7):\n",
        "    split_index = int(split_ratio * len(data))\n",
        "    train_data, test_data = data[:split_index], data[split_index:]\n",
        "    train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "# Function to evaluate KNN with different k values\n",
        "def evaluate_knn(data, labels, k_values):\n",
        "    accuracies = []\n",
        "\n",
        "    for k in k_values:\n",
        "        correct_classifications = 0\n",
        "\n",
        "        for i in range(len(test_data)):\n",
        "            predicted_label = knn_classify(train_data, train_labels, test_data[i], k)\n",
        "            if predicted_label == test_labels[i]:\n",
        "                correct_classifications += 1\n",
        "\n",
        "        accuracy = correct_classifications / len(test_data) * 100\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        print(f'k value: {k}\\nNumber of correctly classified instances: {correct_classifications}\\n'\n",
        "              f'Total number of instances: {len(test_data)}\\nAccuracy: {accuracy:.2f}%\\n')\n",
        "\n",
        "    # Calculate and print average accuracy\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    print(f'Average Accuracy Across All Iterations: {avg_accuracy:.2f}%')\n",
        "\n",
        "# Extract features and labels from the dataset\n",
        "features = df.drop('Outcome', axis=1).values\n",
        "labels = df['Outcome'].values\n",
        "\n",
        "# Normalize features using Min-Max Scaling\n",
        "scaled_features = min_max_scaling(features)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_data, train_labels, test_data, test_labels = train_test_split(scaled_features, labels)\n",
        "\n",
        "# Define k values for iterations\n",
        "k_values = [26, 27, 28]\n",
        "\n",
        "# Evaluate KNN with different k values\n",
        "evaluate_knn(test_data, test_labels, k_values)"
      ]
    }
  ]
}